\section{Frameworks and Technologies}
We have used Django as the backend framework.
Django is a high-level Python web framework that encourages rapid development and clean, pragmatic design.
It is a free and open-source framework that follows the MVC architectural pattern.
More specifically we have used Django REST framework, which is a powerful and flexible toolkit for building RESTFUL APIs.
Django enabled us to have a clean and maintainable codebase while providing a lot of built-in functionalities especially the Django ORM which made it easy to interact with the Postgres database that we utilized. Django REST framework also provided  an easy way to build APIs and serialize this data.
By leveraging Python, we were able to easily connect the backend with OpenAI API, and connect them with the frontend using \textit{channels} which is a socket programming library for Django.

\section{Database}
We used \textbf{Postgresql} which is an open-source relational database management system emphasizing extensibility and SQL compliance.
Postgresql also has a great integration with Django and it is easy to use and maintain.
We did not directly interact with the database, but we used Django ORM which made interaction easy also to make queries and to modify or create tables.

\section{Websockets}
In order to implement the chat functionality we used \textbf{Django Channels}, a project that takes Django and extends its abilities beyond HTTP and API calls.
This allowed us to maintain a persistent connection between the client and the server and send and receive messages in real-time.
Since users were not required to be authenticated to use the chat functionality, we have used a query parameter to identify the user and the conversation they are in.
This also allow us to keep track of all the conversations and messages sent by the different users.
As for the datastore of these conversation (active web-sockets) we have setup a Redis server which is an in-memory data structure store.

\section{OpenAI Integration}
We have used the new OpenAI API for OpenAI assistant. We have already setup our OpenAI assistant with the right context through OpenAI's Playground feature. For each conversation with the user, we store a \textbf{thread\_id} value, which is the conversation ID that allow us to keep track of the conversation, and an OpenAI's thread\_id, which keeps track of the conversation with the OpenAI assistant. Having two different IDs allow us to mask the internal OpenAI's thread\_id.
When a user with a valid thread\_id, that is stored in our database, sends a message, we add it into the user's thread.
This way we can use the context and history of our user's conversation to generate a better response from the LLM.
Since we utilized local storage to store the thread\_id in the front-end, even if the user comes back in a different time, we can still use the previous conversation context. And the user always have the option to delete the history.
A final important note is that the connection to OpenAI is done asynchronously, enabling a much higher scalability.
